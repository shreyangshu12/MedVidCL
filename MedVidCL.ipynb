{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "github.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KChlnM58X8F6"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_text\n",
        "import tensorflow_text as text\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras.layers import *\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "from keras.models import Model\n",
        "from tqdm import tqdm, trange\n",
        "import time\n",
        "import os\n",
        "import torch\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report"
      ],
      "metadata": {
        "id": "lSvrCP1YYSM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor = hub.load(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
        "text_inputs = [tf.keras.layers.Input(shape=(), dtype=tf.string)]\n",
        "tokenize = hub.KerasLayer(preprocessor.tokenize)\n",
        "tokenized_inputs = [tokenize(segment) for segment in text_inputs]\n",
        "seq_length = 512\n",
        "bert_pack_inputs = hub.KerasLayer(preprocessor.bert_pack_inputs, arguments=dict(seq_length=seq_length))\n",
        "encoder_inputs = bert_pack_inputs(tokenized_inputs)\n",
        "encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/4\")\n",
        "outputs = encoder(encoder_inputs)\n",
        "pooled_output = outputs[\"sequence_output\"]\n",
        "embedding_model = tf.keras.Model(text_inputs, pooled_output)"
      ],
      "metadata": {
        "id": "oNAdeOEZYbH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def label_vid(row):\n",
        "    if \"Medical Non-instructional\" in row:\n",
        "        return 0\n",
        "    elif \"Medical Instructional\" in row:\n",
        "        return 1\n",
        "    elif \"Non-medical\" in row:\n",
        "        return 2\n",
        "    else:\n",
        "        return -1\n",
        "\n",
        "def import_datasets(vit_datatype = True):\n",
        "    \n",
        "    datasets = {}\n",
        "    torch_features = {}\n",
        "    # Import JSON files first\n",
        "    json_filenames = [pos_json for pos_json in os.listdir('/content/drive/MyDrive/MedVidCL/data/text') if pos_json.endswith('.json')]\n",
        "    for json_filename in json_filenames:\n",
        "        datasets[json_filename] = pd.read_json('/content/drive/MyDrive/MedVidCL/data/text' + '/' + json_filename)\n",
        "        # Rename columns\n",
        "        datasets[json_filename] = datasets[json_filename].rename(columns = {'video_sub_title':'text', 'video_title':'title', 'label':'labels', 'video_id':'YouTube_ID'})\n",
        "        # Change labels of new datasets to match the old one\n",
        "        datasets[json_filename]['labels'] = datasets[json_filename]['labels'].apply(label_vid)\n",
        "        # Add feature numpy array\n",
        "        if vit_datatype:\n",
        "            datasets[json_filename]['features'] = datasets[json_filename]['YouTube_ID'].apply(lambda x: np.load('/content/drive/MyDrive/MedVidCL/features/ViT/' + json_filename[:-5] + '/' + x + '.npy'))\n",
        "        else:\n",
        "            datasets[json_filename]['features'] = datasets[json_filename]['YouTube_ID'].apply(lambda x: np.load('/content/drive/MyDrive/MedVidCL/features/I3D/' + json_filename[:-5] + '/' + x + '.npy'))\n",
        "        # Convert all numpy arrays to float32\n",
        "        datasets[json_filename]['features'] = datasets[json_filename]['features'].apply(lambda x: x.astype('float32'))\n",
        "        # Convert all numpy arrays to Pytorch tensors\n",
        "        datasets[json_filename]['torch_features'] = datasets[json_filename]['features'].apply(lambda x: torch.Tensor(x))\n",
        "        # Change each feature column to a list\n",
        "        #torch_features[json_filename] = torch.nn.utils.rnn.pad_sequence(datasets[json_filename]['torch_features'].to_list(), batch_first=True, padding_value=0)\n",
        "    \n",
        "    return datasets"
      ],
      "metadata": {
        "id": "OPP6jsL_l38Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasets=import_datasets(False)"
      ],
      "metadata": {
        "id": "Yx9RIB-El502"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train=datasets['train.json'].append(datasets['test.json'])\n",
        "test=datasets['val.json']"
      ],
      "metadata": {
        "id": "YzlK3qTCmj4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['Medical_NonMedical']=train['labels'] ### 0mednoninstr 1medinstr 2nonmed\n",
        "train['Medical_NonMedical'].replace({0:1}, inplace=True)\n",
        "train['Medical_NonMedical'].replace({2:0}, inplace=True)### 0 for Non medical 1 for Medical"
      ],
      "metadata": {
        "id": "H18bhhABalIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_Inst_NonInst = train[train.Medical_NonMedical != 0]"
      ],
      "metadata": {
        "id": "ehPny4_2amJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### for medical non medical\n",
        "x = train['text'].to_numpy()\n",
        "x = np.asarray(x).astype(str)\n",
        "\n",
        "y = pd.get_dummies(train['Medical_NonMedical']).values\n",
        "y = np.asarray(y).astype('float32')\n",
        "\n",
        "text_input = Input(shape=(),dtype=tf.string,name='Text')\n",
        "encode_output = embedding_model(text_input)\n",
        "\n",
        "### bilstm\n",
        "bilstm = Bidirectional(CuDNNLSTM(units=128,return_sequences=False))(encode_output)\n",
        "\n",
        "###Output\n",
        "output = Dense(2,activation='softmax')(bilstm)\n",
        "\n",
        "first_model = Model(inputs=text_input,outputs=output)\n",
        "\n",
        "first_model.compile(loss='categorical_crossentropy',\n",
        "                    optimizer='adam',\n",
        "                    metrics=['accuracy'])\n",
        "\n",
        "first_model.summary()"
      ],
      "metadata": {
        "id": "xzXyMj0EbGSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='accuracy', \n",
        "                                               mode='auto', \n",
        "                                               patience=3, \n",
        "                                               verbose=1)\n",
        "\n",
        "hist = first_model.fit(x, y, \n",
        "                       epochs=50, \n",
        "                       batch_size=8, \n",
        "                       verbose=1,\n",
        "                       callbacks=[early_stopping])"
      ],
      "metadata": {
        "id": "Q85jkoH2g_hS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### vid_features extract\n",
        "train_vidf=np.zeros((len(train_Inst_NonInst),2,1024))\n",
        "tmp=train_Inst_NonInst['features'].to_numpy()\n",
        "for i in range(len(train_Inst_NonInst)):\n",
        "  train_vidf[i]=tmp[i]\n",
        "\n",
        "test_vidf=np.zeros((len(test),2,1024))\n",
        "tmp=test['features'].to_numpy()\n",
        "for i in range(len(test)):\n",
        "  test_vidf[i]=tmp[i]"
      ],
      "metadata": {
        "id": "XJz_ZCpri8qx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = pd.get_dummies(train_Inst_NonInst['labels']).values\n",
        "y = np.asarray(y).astype('float32')"
      ],
      "metadata": {
        "id": "KdFPQWJymtK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### for medical instructional and medical non instructional\n",
        "x_text = train_Inst_NonInst['text'].to_numpy()\n",
        "x_text = np.asarray(x_text).astype(str)\n",
        "\n",
        "### Video features\n",
        "vid_features_input = Input(shape=(2,1024),name='VidFeatures')\n",
        "\n",
        "### bilstm\n",
        "bilstm_vid = Bidirectional(CuDNNLSTM(units=128,return_sequences=False))(vid_features_input)\n",
        "\n",
        "### Video features dense\n",
        "vid_features_data = Dense(1024)(bilstm_vid)\n",
        "\n",
        "### Text \n",
        "text_input = Input(shape=(),dtype=tf.string,name='Text')\n",
        "encode_output = embedding_model(text_input)\n",
        "\n",
        "### bilstm\n",
        "bilstm = Bidirectional(CuDNNLSTM(units=128,return_sequences=False))(encode_output)\n",
        "\n",
        "### Text dense\n",
        "text_data = Dense(1024)(bilstm)\n",
        "\n",
        "concat = concatenate([text_data, vid_features_data])\n",
        "output = Dense(2, activation='softmax')(concat)\n",
        "\n",
        "second_model = Model(inputs=[text_input,vid_features_input],outputs=output)\n",
        "\n",
        "second_model.compile(loss='categorical_crossentropy',\n",
        "                    optimizer='adam',\n",
        "                    metrics=['accuracy'])\n",
        "\n",
        "second_model.summary()"
      ],
      "metadata": {
        "id": "TaNemBrahMxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = keras.callbacks.EarlyStopping(monitor='accuracy', \n",
        "                                               mode='auto', \n",
        "                                               patience=3, \n",
        "                                               verbose=1)\n",
        "\n",
        "hist = second_model.fit([x_text, train_vidf], y, \n",
        "                       epochs=1, \n",
        "                       batch_size=8, \n",
        "                       verbose=1,\n",
        "                       steps_per_epoch=2,\n",
        "                       callbacks=[early_stopping])"
      ],
      "metadata": {
        "id": "N8wJ04aqhoFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_pred=first_model.predict(test['text'])\n",
        "second_pred=second_model.predict([test['text'],test_vidf])"
      ],
      "metadata": {
        "id": "173NXxFCZxpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=[]\n",
        "for i in range(len(test)):\n",
        "    tmp=first_pred[i]\n",
        "    tmp=np.argmax(tmp)\n",
        "    if tmp == 0:\n",
        "        y_pred.append(2)\n",
        "    \n",
        "    else:\n",
        "        tmp=second_pred[i]\n",
        "        tmp=np.argmax(tmp)\n",
        "\n",
        "        if tmp == 0:\n",
        "            y_pred.append(0)\n",
        "        else:\n",
        "            y_pred.append(1)\n"
      ],
      "metadata": {
        "id": "w5GNviY8rUPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_real=test['labels'].to_list()\n",
        "print(classification_report(y_true=y_real,\n",
        "                            y_pred=y_pred,\n",
        "                            labels=list(set(test['labels'])),\n",
        "                            digits=4))"
      ],
      "metadata": {
        "id": "CrxUoVrasDhg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}